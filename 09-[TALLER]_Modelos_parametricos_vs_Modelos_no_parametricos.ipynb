{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "09-[TALLER]_Modelos_parametricos_vs_Modelos_no_parametricos.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ou6N0gCA0Stg"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/blob/master/09-[TALLER]_Modelos_parametricos_vs_Modelos_no_parametricos.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
        "\n",
        "\n",
        "**Recuerda que una vez abierto, Da clic en \"Copiar en Drive\", de lo contrario no podras alamancenar tu progreso**\n",
        "\n",
        "Nota: no olvide ir ejecutando las celdas de código de arriba hacia abajo para que no tenga errores de importación de librerías o por falta de definición de variables."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvvrLVTb0Stp"
      },
      "source": [
        "!wget --no-cache -O init.py -q https://raw.githubusercontent.com/UDEA-Esp-Analitica-y-Ciencia-de-Datos/EACD-04-MACHINE-LEARNING-1/master/init.py\n",
        "import init; init.init(force_download=False); "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RUolHa1K0Str"
      },
      "source": [
        "# Taller - Parte 1\n",
        "\n",
        "**Clasificación**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vPJ6mCVY0Str"
      },
      "source": [
        "## Ejercicio 1: Contextualización del problema\n",
        "\n",
        "\n",
        "Usaremos el dataset digits para el problema de clasificación. En el repositorio de sklearn se encuentra más información en el siguiente [link](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_digits.html) ."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fEeIn-DP0Sts"
      },
      "source": [
        "#configuración del laboratorio\n",
        "# Ejecuta esta celda!\n",
        "%load_ext autoreload\n",
        "%autoreload 2\n",
        "# for local \n",
        "\n",
        "from local.lib.general import configure_lab2\n",
        "configure_lab2()\n",
        "from local.lib.lab2 import *\n",
        "GRADER, x, y = part_1()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BgpA3KSs0Sts"
      },
      "source": [
        "print (\"Número de muestras\", x.shape[0])\n",
        "print (\"Número de variables\", x.shape[1])\n",
        "print (\"Número de clases\", len(np.unique(y)))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z299Q_eC0Sts"
      },
      "source": [
        "real_data = x[:44].reshape((4, 11, -1))\n",
        "fig, ax = plt.subplots(5, 11, subplot_kw=dict(xticks=[], yticks=[]),figsize=(15,8))\n",
        "for j in range(11):\n",
        "    ax[4, j].set_visible(False)\n",
        "    for i in range(4):\n",
        "        im = ax[i, j].imshow(real_data[i, j].reshape((8, 8)),\n",
        "                             cmap=plt.cm.binary, interpolation='nearest')\n",
        "        im.set_clim(0, 16)\n",
        "ax[0, 5].set_title('Selection from the input data')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TJ7ewoMw0Sts"
      },
      "source": [
        "En un problema de clasificación de más de una clase, tener un desbalance de muestras puede ser perjudicial para el proceso de entrenamiento. Vamos a crear una función para verificar el numero de muestras por clases."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DzlVzODE0Stt"
      },
      "source": [
        "#Ejercicio de código\n",
        "def muestras_por_clases (Y):\n",
        "    \"\"\"Funcion que calcula el numero de muestras por cada clase\n",
        "    Y: vector de numpy con las etiquetas de las muestras del conjunto X\n",
        "    retorna: diccionario [int/float:int/float] \n",
        "        con la estructura:{etiquetaclase1: numero de muestras clase1, etiquetaclase2: numero de muestras clase2}\n",
        "    \"\"\"\n",
        "    dicto = {}\n",
        "    ## Pista se puede asginar keys a diccionario: dict[etiqueta] = valor\n",
        "          \n",
        "\n",
        "    return (dicto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xp4M2Us_0Stt"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1.1\", muestras_por_clases)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "14OoTJrE0Stt"
      },
      "source": [
        "# con esta linea de codigo puedes ver la dsitribucion de forma grafica\n",
        "fig, ax = plt.subplots()\n",
        "ax.bar(muestras_por_clases(y).keys(), muestras_por_clases(y).values())\n",
        "ax.set_title(\"numero de muestras por clase\")\n",
        "ax.set_xlabel(\"etiqueta de clase\")\n",
        "ax.set_ylabel(\"# muestras por clase\")\n",
        "ax.set_xticks(list(muestras_por_clases(y).keys()))\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JiBn6SiV0Stt"
      },
      "source": [
        "## Ejercicio 2: \n",
        "\n",
        "\n",
        "Los modelos que provaremos en este taller son:\n",
        "\n",
        "- Naïve Bayes\n",
        "- Discriminante Cuadrático\n",
        "- K-NN\n",
        "- Parzen Window\n",
        "\n",
        "De todos ellos el único que no tiene implementación como modelo de clasificación es el último, por lo tanto el objetivo de este punto es programar una clase en python que permita definir clasificadores basados en **Parzen Window**, debe contener un constructor para definir el ancho de la ventana, un método .fit y un método .predict que reciba una matriz de datos (muestras,variables) y retorne la clase asignada a cada muestra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fb8MZe7D0Stu"
      },
      "source": [
        "#Ejercicio de código\n",
        "from sklearn.neighbors import KernelDensity\n",
        "\n",
        "class ParzenWindowClassifier():\n",
        "    \n",
        "    def __init__ (self, bandwidth):\n",
        "        self.bandwidth = bandwidth\n",
        "        \n",
        "        #Se sugiere tener una variable para almacenar el número de clases\n",
        "        self.num_clases = 0\n",
        "        #Se sugiere tener una lista para almacenar la ventanas de Parzen entrenadas para cada clase\n",
        "        self.kernelDensity = []\n",
        "    \n",
        "    def fit(self,X,Y):\n",
        "        \"\"\"Esta funcion es encargada entrenar el modelo, se deben entrenar las distribuciones kernel para cada clase.\n",
        "        \n",
        "            Se sugiere verificar que el conjunto de entrada tenga más de dos clases\n",
        "        \"\"\"\n",
        "        clases = np.unique(Y)\n",
        "        for i in range(clases):\n",
        "            X2 = X[Y==i,:]\n",
        "            self.kernelDensity.append(KernelDensity(self.bandwidth).fit(X2))\n",
        "        \n",
        "        return self\n",
        "        \n",
        "    def predict(self,X_val):\n",
        "        \"\"\"Esta funcion es encargada de realizar una predicción con base en las \n",
        "        muestras almacenadas y el ancho de banda definido, para cada una de las muestras en X_val.\n",
        "        \"\"\"\n",
        "                        \n",
        "        #Debe retornar un vector que contenga las predicciones para cada una de las muestras en X_val, \n",
        "        #en el mismo orden y la matriz con las probabilidades por clase\n",
        "        return class_est, prob"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yqdmNoaD0Stv"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio1.2\", ParzenWindowClassifier)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PMZzjSVV0Stw"
      },
      "source": [
        "## Ejercicio 3:\n",
        "\n",
        "En este ejercicio vamos a hacer simulaciones con los diferentes modelos y a seleccionar los hiperparámetros con mejor desempeño. Carguemos los modelos a comparar:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VFLm1hH0Stx"
      },
      "source": [
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WoEVm8Bx0Stx"
      },
      "source": [
        "#Dejamos algunas muestras para el proceso de entrenamiento y otras para evaluar qué tan bueno fue el aprendizaje del modelo\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "random.seed(1)\n",
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "\n",
        "\n",
        "#Normalizamos\n",
        "scaler = StandardScaler().fit(Xtrain)\n",
        "Xtrain = scaler.transform(Xtrain)\n",
        "Xtest = scaler.transform(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xL3SRjrH0Sty"
      },
      "source": [
        "Instanciamos y entrenamos los modelos para algunos hiperparámetros por defecto:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u2ClQxdU0Sty"
      },
      "source": [
        "clf = []\n",
        "clf.append(GaussianNB().fit(Xtrain,Ytrain))\n",
        "clf.append(QuadraticDiscriminantAnalysis().fit(Xtrain,Ytrain))\n",
        "clf.append(KNeighborsClassifier(n_neighbors=1).fit(Xtrain,Ytrain))\n",
        "clf.append(ParzenWindowClassifier(bandwidth=0.1).fit(Xtrain,Ytrain))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KAfk_wV50Stz"
      },
      "source": [
        "Veamos cómo se comportan para algunas muestras de test. **Ejecute la celda varias veces para observar diferentes resultados**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "bOnY8diH0Stz"
      },
      "source": [
        "ind = np.random.permutation(Xtest.shape[0])[0]\n",
        "print('real class')\n",
        "print(Ytest[ind])\n",
        "\n",
        "for i in range(4):\n",
        "    if i==3:\n",
        "        _,preds = clf[i].predict(Xtest[ind,:].reshape(1,-1))\n",
        "    else:\n",
        "        preds = clf[i].predict_proba(Xtest[ind,:].reshape(1,-1))\n",
        "    y_pos = np.arange(len(np.unique(y)))\n",
        "    performance = preds.flatten()\n",
        "    plt.subplot(121)\n",
        "    plt.imshow(Xtest[ind,:].reshape(8,8), cmap='gray');\n",
        "    plt.subplot(122) \n",
        "    plt.barh(y_pos, performance, align='center', alpha=0.5)\n",
        "    plt.yticks(y_pos, np.unique(y))\n",
        "    plt.xlabel('Probability')\n",
        "    plt.title('Models outputs')\n",
        "    plt.subplots_adjust(wspace = 1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OeU_xDeC0Stz"
      },
      "source": [
        "Evaluemos el desempeño en todo el conjunto de test para diferentes hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2_HCtK00St0"
      },
      "source": [
        "#Ejercicio de código\n",
        "from sklearn.metrics import accuracy_score\n",
        "k = range(1,16)\n",
        "h = np.linspace(0.001,10,15)\n",
        "acc_knn = []\n",
        "acc_pw = []\n",
        "for i in range(len(k)):\n",
        "    clf1 = KNeighborsClassifier(n_neighbors=k[i]).fit(Xtrain,Ytrain)\n",
        "    clf2 = ParzenWindowClassifier(bandwidth=h[i]).fit(Xtrain,Ytrain)\n",
        "    y_pred_knn = \n",
        "    y_pred_pw,_ = \n",
        "    acc_knn.append(accuracy_score(Ytest,y_pred_knn)) \n",
        "    acc_pw.append(accuracy_score(Ytest,y_pred_pw)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ymMkXG3r0St0"
      },
      "source": [
        "Grafiquemos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Tc8oUUdF0St0"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(k,np.array(acc_knn))\n",
        "plt.title('Desempeño para el k-nn')\n",
        "plt.xlabel('Número de vecinos')\n",
        "plt.ylabel('Exactitud')\n",
        "plt.grid()\n",
        "plt.subplot(122)\n",
        "plt.plot(h,np.array(acc_pw))\n",
        "plt.title('Desempeño para el método kernel')\n",
        "plt.xlabel('Ancho de banda')\n",
        "plt.ylabel('Exactitud')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DkupYW720St0"
      },
      "source": [
        "print(f'Mejore resultado para k-nn {np.max(np.array(acc_knn))}')\n",
        "print(f'Mejore resultado para PW {np.max(np.array(acc_pw))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQ0vGZFl0St1"
      },
      "source": [
        "Mida el desempeño para los Modelos Naïve Bayes y Discriminante Cuadrático:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9RIRhgvh0St1"
      },
      "source": [
        "#Ejercicio de código\n",
        "clf = GaussianNB().fit(Xtrain,Ytrain)\n",
        "y_pred_nb = clf.predict(Xtest)\n",
        "\n",
        "clf = QuadraticDiscriminantAnalysis().fit(Xtrain,Ytrain)\n",
        "y_pred_qd = clf.predict(Xtest)\n",
        "\n",
        "print(f'Mejore resultado para Naïve Bayes {accuracy_score(Ytest,y_pred_nb)}')\n",
        "print(f'Mejore resultado para Discriminante Cuadrático {accuracy_score(Ytest,y_pred_qd)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iRNbL6s0St1"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿Cuáles tipos de modelos obtuvieron mejores resultados?\n",
        "respuesta_1 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L1EIT4OK0St1"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  ¿Cuál fue el modelo con peor desempeño? ¿Cuál cree que es la razón para dicho comportamiento?\n",
        "respuesta_2 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gn9OOeXj0St2"
      },
      "source": [
        "Grafique la matriz de confusión normalizada del mejor modelo."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0cHPxhK0St2"
      },
      "source": [
        "#Ejercicio de código"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dC7MNejB0St2"
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IJ6E7pZJ0St2"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RjpvA0hT0St3"
      },
      "source": [
        "----\n",
        "Esta linea es de uso exclusivo del los profesores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XQaJG7Hp0St3"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6WaAkiD0St4"
      },
      "source": [
        "# Taller - Parte 2\n",
        "\n",
        "**Regresión**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qD9g2XZ_0St4"
      },
      "source": [
        "GRADER, x, y = part_2()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MyZojhrc0St5"
      },
      "source": [
        "## Ejercicio 2.1: Contextualización del problema\n",
        "\n",
        "Para el problema de regresion usaremos la base de datos 'The Boston Housing Dataset', cuya descripción [pueden encontrarla aqui](https://www.cs.toronto.edu/~delve/data/boston/bostonDetail.html). La información ya esta cargada dentro del notebook"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEalgDBv0St5"
      },
      "source": [
        "print(\"muestra de los 3 primeros renglones de x:\\n\", x[0:3, :])\n",
        "print(\"muestra de los 3 primeros renglones de y:\\n\", y[0:3])\n",
        "print (\"Número de muestras\", x.shape[0])\n",
        "print (\"Número de variables\", x.shape[1])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0Z6EHJ_v0St6"
      },
      "source": [
        "En los problemas de regresión, es muy util explorar la distribución de la variable objetivo. Nuestro primer ejercicio consiste en:\n",
        "1. visualizar un histograma de la variable y \n",
        "2. retornar los intervalo de datos mas frecuente.\n",
        "\n",
        "Pistas: \n",
        "1. explorar la documentación de [plt.hist](https://matplotlib.org/3.3.1/api/_as_gen/matplotlib.pyplot.hist.html). Maneje los valores por defecto. ¿como se puede usar la salida del histograma para retorna el intervalo de datos mas frecuente?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5uW1PKX0St6"
      },
      "source": [
        "#ejercicio de código\n",
        "def plot_hist_and_get_freq_int(Y):\n",
        "    \"\"\"función que grafica el histograma de la variable 'Y'\n",
        "        y retorna el intervalo donde ocurren con mas frecuencia los\n",
        "        valores de 'Y'\n",
        "        Y: numpy array con la variable a graficar\n",
        "        retorna: una tupla (int/float, int/float, int/float) \n",
        "            el primer elemento es el limite inferior del intervalo donde ocurren los valores\n",
        "            mas frecuentes\n",
        "            el segundo elemento es el limite superior del intervalo donde ocurren los valores\n",
        "            mas frecuentes\n",
        "            el tercer elemento es la frecuencia del intervalo anterior\n",
        "            va observar un cuarto elemento a retornar, el cual es usado para confirmar que\n",
        "            se realizo la grafica correctamente\n",
        "    \"\"\"\n",
        "    \n",
        "    plt.hist()\n",
        "    lim_inf = \n",
        "    lim_sup = \n",
        "    freqs = \n",
        "    \n",
        "    # el cuarto elemento debe dejarlo\n",
        "    return (lim_inf, lim_sup, freqs, plt.gcf())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8ytYFRTh0St6"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "#ignora las graficas!!\n",
        "GRADER.run_test(\"ejercicio2.1\", plot_hist_and_get_freq_int)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jCDawlNK0St7"
      },
      "source": [
        "# ver el histograma!\n",
        "plot_hist_and_get_freq_int(y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WOGEcVnA0St7"
      },
      "source": [
        "Debemos nuevamente partir el conjunto de muestras en entrenamiento y test y normalizar."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zZ6QgQs00St7"
      },
      "source": [
        "Xtrain, Xtest, Ytrain, Ytest = train_test_split(x, y, test_size=0.3, random_state=1)\n",
        "\n",
        "#Normalizamos\n",
        "scaler = StandardScaler().fit(Xtrain)\n",
        "Xtrain = scaler.transform(Xtrain)\n",
        "Xtest = scaler.transform(Xtest)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jr1_FiSv0St7"
      },
      "source": [
        "## Ejercicio 2.2: \n",
        "\n",
        "Los modelos que provaremos en este taller son:\n",
        "\n",
        "- Linearn regression\n",
        "- K-NN\n",
        "- Parzen Window (Nadaraya_Watson estimator)\n",
        "\n",
        "De todos ellos el único que no tiene implementación estándar en sklearn como modelo de regresión es el último, por lo tanto el objetivo de este punto es programar una clase en python que permita definir regresores basados en **Parzen Window**, debe contener un constructor para definir el ancho de la ventana, un método .fit y un método .predict que reciba una matriz de datos (muestras,variables) y retorne la predicción asignada a cada muestra."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TWMBqF8r0St7"
      },
      "source": [
        "#Ejercicio de código\n",
        "from sklearn.metrics.pairwise import pairwise_kernels\n",
        "\n",
        "class ParzenWindowRegressor():\n",
        "    \n",
        "    def __init__ (self, bandwidth):\n",
        "        self.bandwidth = bandwidth\n",
        "\n",
        "        #Training Data\n",
        "        self.X = []\n",
        "        self.Y = []\n",
        "    \n",
        "    def fit(self,x,y):\n",
        "        \"\"\"Esta funcion es encargada entrenar el modelo que para el caso\n",
        "        de la venatan de Parzen consiste en almacenar las muestras de entrenamiento.\n",
        "        \"\"\"\n",
        "          \n",
        "        return self\n",
        "        \n",
        "    def predict(self,X_val):\n",
        "        \"\"\"Esta funcion es encargada de realizar una predicción con base en las \n",
        "        muestras almacenadas y el ancho de banda definido, para cada una de las muestras en X.\n",
        "        \n",
        "        Se sugiere usar el método pairwise_kernels y evitar las divisiones por 0 en el estimador Nadarata-Watson, \n",
        "        reemplazando el valor de predicción directamente por cero.\n",
        "        \"\"\"\n",
        "               \n",
        "\n",
        "        return y_est\n",
        "                "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FXbdPWYH0St8"
      },
      "source": [
        "## la funcion que prueba tu implementacion\n",
        "GRADER.run_test(\"ejercicio2.2\", ParzenWindowRegressor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ktG3cUM30St8"
      },
      "source": [
        "Carguemos los modelos restantes:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QFMp1ZXa0St8"
      },
      "source": [
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.linear_model import LinearRegression"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z22bt4IW0St8"
      },
      "source": [
        "Evaluemos el desempeño en todo el conjunto de test para diferentes hiperparámetros"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQE5zmTW0St8"
      },
      "source": [
        "#Ejercicio de código\n",
        "from sklearn.metrics import mean_squared_error\n",
        "k = range(1,16)\n",
        "h = np.linspace(0.001,1,15)\n",
        "mse_knn = []\n",
        "mse_pw = []\n",
        "for i in range(len(k)):\n",
        "    clf1 = KNeighborsRegressor(n_neighbors=k[i]).fit(Xtrain,Ytrain)\n",
        "    clf2 = ParzenWindowRegressor(bandwidth=h[i]).fit(Xtrain,Ytrain)\n",
        "    y_pred_knn = \n",
        "    y_pred_pw = \n",
        "    mse_knn.append(mean_squared_error(Ytest,y_pred_knn)) \n",
        "    mse_pw.append(mean_squared_error(Ytest,y_pred_pw)) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z6A5PoEy0St8"
      },
      "source": [
        "Grafiquemos el resultado:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ou168pDQ0St9"
      },
      "source": [
        "plt.figure(figsize=(10,5))\n",
        "plt.subplot(121)\n",
        "plt.plot(k,np.array(mse_knn))\n",
        "plt.title('Desempeño para el k-nn')\n",
        "plt.xlabel('Número de vecinos')\n",
        "plt.ylabel('MSE')\n",
        "plt.grid()\n",
        "plt.subplot(122)\n",
        "plt.plot(h,np.array(mse_pw))\n",
        "plt.title('Desempeño para el método kernel')\n",
        "plt.xlabel('Ancho de banda')\n",
        "plt.ylabel('MSE')\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "br4wiSoC0St9"
      },
      "source": [
        "print(f'Mejore resultado para k-nn {np.min(np.array(mse_knn))}')\n",
        "print(f'Mejore resultado para PW {np.min(np.array(mse_pw))}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mJKYyGnI0St9"
      },
      "source": [
        "Mida el desempeño de la regresión lineal:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZMF4Jex0St9"
      },
      "source": [
        "#Ejercicio de código\n",
        "clf = LinearRegression().fit(Xtrain,Ytrain)\n",
        "y_pred_lr = clf.predict(Xtest)\n",
        "\n",
        "print(f'Mejore resultado para LR {mean_squared_error(Ytest,y_pred_lr)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yCUdtE-00St9"
      },
      "source": [
        "En términos de error absoluto medio, ¿cuál es el nivel de error del mejor modelo?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-xfjyT10St9"
      },
      "source": [
        "#Ejercicio de código\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-HyzdlV0St-"
      },
      "source": [
        "#@title Pregunta Abierta\n",
        "#@markdown  Con base en los resultados obtenidos, ¿cuál considera que es el problema de los modelos paramétricos evaluados? \n",
        "respuesta_3 = \"\" #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A7IeM8E10St-"
      },
      "source": [
        "GRADER.check_tests()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS2j-6dp0St-"
      },
      "source": [
        "#@title Integrantes\n",
        "codigo_integrante_1 ='' #@param {type:\"string\"}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XJdzS3Sv0St-"
      },
      "source": [
        "----\n",
        "Esta linea de codigo es de uso exclusivo del los profesores"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H45jzUQ0St-"
      },
      "source": [
        "GRADER.grade()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}